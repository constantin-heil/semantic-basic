{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example of getting embeddings and using vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections.abc import Sequence\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key is stored in a file that is not tracked by the repo. Paste the key obtained from OpenAI into secretkey.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_SECRET_FN = \"secretkey.txt\"\n",
    "\n",
    "with open(API_SECRET_FN, \"r\") as fh:\n",
    "    APIKEY = fh.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to send embedding request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(inp_text: str) -> list:\n",
    "    \"\"\"Send natural language text to OpenAI Embeddings API\n",
    "\n",
    "    Args:\n",
    "        input_text (str): A string that represents the input\n",
    "\n",
    "    Returns:\n",
    "        list: list of embeddings\n",
    "    \"\"\"\n",
    "    header = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {APIKEY}\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"input\": inp_text,\n",
    "        \"model\": \"text-embedding-ada-002\"\n",
    "    }\n",
    "    \n",
    "    result = requests.post(\n",
    "        url = \"https://api.openai.com/v1/embeddings\",\n",
    "        headers = header,\n",
    "        json = data\n",
    "    )\n",
    "    \n",
    "    return json.loads(result.content)[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are 6 sentences, chosen as to be from 2 different semantics contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"burgers are good\",\n",
    "    \"I love kebab\",\n",
    "    \"Fries are the best\",\n",
    "    \"I fix cars\",\n",
    "    \"airplanes are easy to repair\",\n",
    "    \"sometimes boats can break\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain embeddings for the toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = [get_embeddings(txt) for txt in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store embeddings in database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am here working with a postgresql database that runs from a docker container defined in ./database .\n",
    "\n",
    "We activate the vector extension, which allows for the main functionalities:\n",
    "* Storing of vector of variable length\n",
    "* Distance operations against a query vector\n",
    "* Index generation of the vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish connection to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql+psycopg2://root:password@localhost:5432/postgres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert embeddings into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as c:\n",
    "    for i in range(len(embs)):\n",
    "        params = {\n",
    "            \"insemb\": str(embs[i]).replace(\" \", \"\"),\n",
    "            \"rawtext\": texts[i]\n",
    "            }\n",
    "        c.execute(text(\"insert into embed (rawtext, embeddings) values (:rawtext, :insemb)\"), parameters = params)\n",
    "    \n",
    "    c.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get distance from a query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort table by cosine distance from a query. Since default ordering is ASC, the closest embeddings are on top.\n",
    "\n",
    "Note how the distances differ between the 2 contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0727817242665948, 'burgers are good')\n",
      "(0.20274515086528044, 'I love kebab')\n",
      "(0.08842932123787695, 'Fries are the best')\n",
      "(0.2441495830388496, 'I fix cars')\n",
      "(0.2594703722631435, 'airplanes are easy to repair')\n",
      "(0.2721928901212477, 'sometimes boats can break')\n"
     ]
    }
   ],
   "source": [
    "querytext = \"burgers go great with fries\"\n",
    "queryemb = get_embeddings(querytext)\n",
    "\n",
    "with engine.connect() as c:\n",
    "    res = c.execute(text(\"select embeddings <=> :qemb, rawtext from embed;\"), parameters = {\"qemb\": str(queryemb).replace(\" \", \"\")})\n",
    "    \n",
    "for r in res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is trivial with this small dataset, but is included only to show the method.\n",
    "\n",
    "Vector columns can be indexed using IVFFlat, which used approximate nearest neighbors (ANN) to map vectors to clusters, i.e. Cluster centers have a mapping to the vectors within the respective clusters.\n",
    "\n",
    "An important parameter in the process is the amount of such lists. More lists mean faster search but worse recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as c:\n",
    "    c.execute(text(\"CREATE INDEX ON embed USING ivfflat (embeddings vector_cosine_ops) WITH (lists = 1)\"))\n",
    "    c.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
